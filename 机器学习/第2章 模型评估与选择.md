# 第2章 模型评估与选择

部分内容不一定在书中

## 过拟合与欠拟合

- 过拟合 (overfitting)：对训练样本学习过度，导致泛化性能下降（此问题无法彻底避免）
  - 解决方法：正则化等
- 欠拟合 (underfitting)：对训练样本学习不足，导致泛化性能不足
  - 解决方法：增加训练轮数等

## 误差分类

- 期望风险：对所有样本（包含未知样本和已知的训练样本）的预测能力
  - 反映模型的泛化能力
  - 在实际操作中往往用测试误差作为泛化误差的近似
  - **测试集应尽可能与训练集互斥，但需要同分布**
- 经验风险：对已知的训练样本的预测能力
  - 反映了训练误差
  - **过分追求经验误差（风险）最小化容易导致过拟合问题**
- 结构风险：反映了模型的复杂度（例如参数维度）
  - 可以认为**期望风险 = 经验风险 + 结构风险**，因此在选择模型和衡量误差时希望追求经验风险最小化以及结构风险最小化的平衡 （进一步引申：VC维）
  - 常用方法：添加正则项：比如“**L1正则化”、“L2正则化**”

## 数据集划分方法

- 留出法：直接将数据集D 划分为两个互斥的集合
  - 训练/测试集的划分要尽可能保持数据分布的一致性，避免因数据划分过程引入额外的偏差而对最终结果产生影响
  - 在分类任务中至少要保持样本的类别比例相似
  - 优点：简单
  - 缺点：单次使用留出法得到的估计结果往往**不够稳定可靠，需多次重复求平均**
  - 常见做法是将大约2/3~4/5的样本用于训练，剩余样本用于测试
- 交叉验证法：将数据集D划分为k个大小相似的**互斥**子集，即![](https://latex.codecogs.com/gif.latex?D=D_{1}&space;\cup&space;D_{2}&space;\cup&space;\ldots&space;\cup&space;D_{k},&space;D_{i}&space;\cap&space;D_{j}=\varnothing(i&space;\neq&space;j))，每个子集都尽可能保证数据分布的一致性，即从D 中通过分层采样得到.每次用k-1 个子集的并集作为训练集，余下的那个子集作为测试集；这样就可获得k组训练/测试集，从而可进行k次训练和测试，最终返回的是这k个测试结果的均值
  - 常用10折交叉
  - 特殊情况：留一法
- 自助法：从数据集D中有放回的抽取样本组成训练集D’ （D与D’的样本数相同但样本分布有所不同，大约有36.8%的样本不会被包含在采样数据集中），于是可以用D‘作为训练集，D\D’作为测试集
  - 优点：
    - 在数据集较小、难以有效划分训练/测试集时很有用
    - 能从初始数据集中**产生多个不同的训练集**，对集成学习等方法有很大的好处
  - 缺点：
    - 改变了初始数据集的分布，这会**引入估计偏差**

## 采样方法

分层采样：保留类别比例的采样方式

## 调参

- 参数范围
  - 超参数可以变化的范围
- 移动步长
  - 超参数的调整步长
- 流程
  - 分割数据集为
    - 训练集（见第一章）
    - 测试集（见第一章）
    - 验证集（validation set）：可以认为验证集是用来调参的，即同一模型可以有多组超参数（hyper-parameters），每次调整参数后在验证集中验证模型性能，从而选出较优的超参组合。测试集由始至终都不能参与到训练和参数调整中，如此才能保证泛化能力估计的准确性，如果使用测试集来进行参数调整，相当于学习器学习了测试集中的内容，此时测试集对于学习器就不是一个全新的内容，不符合估计泛化能力的要求。

- 引申
  - 调参记录：fitlog，tensorboardx等
  - 自动调参：AutoML（grid search，random search，NAS等）

## 评估指标

### 回归任务

- 均方误差
  - ![](https://latex.codecogs.com/gif.latex?E%28f%20%3B%20D%29%3D%5Cfrac%7B1%7D%7Bm%7D%20%5Csum_%7Bi%3D1%7D%5E%7Bm%7D%5Cleft%28f%5Cleft%28x_%7Bi%7D%5Cright%29-y_%7Bi%7D%5Cright%29%5E%7B2%7D)

### 分类任务

- 精度/准确率（accuracy）

  - ![](https://latex.codecogs.com/gif.latex?E%28f%20%3B%20D%29%3D%5Cfrac%7B1%7D%7Bm%7D%20%5Csum_%7Bi%3D1%7D%5E%7Bm%7D%20%5Cmathbb%7BI%7D%5Cleft%28f%5Cleft%28%5Cboldsymbol%7Bx%7D_%7Bi%7D%5Cright%29%20%5Cneq%20y_%7Bi%7D%5Cright%29)

- 错误率

  - ![](https://latex.codecogs.com/gif.latex?%5Cbegin%7Baligned%7D%20%5Coperatorname%7Bacc%7D%28f%20%3B%20D%29%20%26%3D%5Cfrac%7B1%7D%7Bm%7D%20%5Csum_%7Bi%3D1%7D%5E%7Bm%7D%20%5Cmathbb%7BI%7D%5Cleft%28f%5Cleft%28%5Cboldsymbol%7Bx%7D_%7Bi%7D%5Cright%29%3Dy_%7Bi%7D%5Cright%29%20%5C%5C%20%26%3D1-E%28f%20%3B%20D%29%20%5Cend%7Baligned%7D)

- 混淆矩阵

  - |              |            预测结果            |            预测结果            |
    | :----------: | :----------------------------: | :----------------------------: |
    | **真实情况** |              正例              |              反例              |
    |     正例     | TP（真正例，预测为真实际为真） | FN（假反例，预测为假实际为真） |
    |     反例     | FP（假正例，预测为真实际为假） | TN（真反例，预测为反实际为反） |

- 查准率（precision）

  - ![](https://latex.codecogs.com/svg.latex?P=\frac{TP}{TP+FP})
- 查全率（recall）/ 真正例率（TPR）

  - ![$R=\frac{T P}{T P+F N}$](https://latex.codecogs.com/gif.latex?R%3D%5Cfrac%7BT%20P%7D%7BT%20P&plus;F%20N%7D)

- P-R曲线

  - ![image-20200613104733753](https://i.loli.net/2020/06/13/gVJCbOc7Sxvf8G3.png)
  - 衡量方法
    - 曲线下面积（不易估算）
    - 平衡点(Break-Event Point，简称BEP)：是" 查准率=查全率"时的取值，BEP越大学习器效果越好
    - F1度量（基于查准率和查全率的调和平均）
      - ![$\frac{1}{F 1}=\frac{1}{2} \cdot\left(\frac{1}{P}+\frac{1}{R}\right)$](https://latex.codecogs.com/gif.latex?%5Cfrac%7B1%7D%7BF%201%7D%3D%5Cfrac%7B1%7D%7B2%7D%20%5Ccdot%5Cleft%28%5Cfrac%7B1%7D%7BP%7D&plus;%5Cfrac%7B1%7D%7BR%7D%5Cright%29)
      - ![](https://latex.codecogs.com/gif.latex?F&space;1=\frac{2&space;\times&space;P&space;\times&space;R}{P&plus;R}=\frac{2&space;\times&space;T&space;P}{\text&space;{&space;Example&space;Counts&space;}&plus;T&space;P-T&space;N})
    - $f_{\beta}$度量
      - ![](https://latex.codecogs.com/gif.latex?\frac{1}{F_{\beta}}=\frac{1}{1&plus;\beta^{2}}&space;\cdot\left(\frac{1}{P}&plus;\frac{\beta^{2}}{R}\right))
      - ![](https://latex.codecogs.com/gif.latex?F_{\beta}=\frac{\left(1&plus;\beta^{2}\right)&space;\times&space;P&space;\times&space;R}{\left(\beta^{2}&space;\times&space;P\right)&plus;R})
    - 当存在多个混淆矩阵时（如多次训练，多个数据集，多分类任务）
      - 宏F1（macro-F1）：先求每个混淆矩阵中的查准率和查全率，再计算其平均值，最后根据F1计算公式计算得到宏F1
      - 微F1（micro-F1）：先求TP, FP, TN, FN的平均值，再基于这些平均值求微查准率，微查全率以及微F1

- 受试者工作特征（ROC，Receiver Operating Characteristic）曲线

  - 每个样本经过模型后能够得到一个预测的分数，根据这个分数我们可以对样本进行排序，"最可能"是正例的排在最前面，"最不可能"是正例的排在最后面，我们根据人为设定的截断点可以将样本分为两部分，前半部分判为正例，后半部分判为负例
  - 更重视"查准率"，则可选择排序中靠前的位置进行截断;若更重视"查全率"，则可选择靠后的位置进行截断
  - ROC曲线的横轴是“假正例率” （FPR），纵轴是“真正例率” （TPR）
  - 通过人为设置多个不同的截断点（可以根据每个样本的分数来作为阈值），每个截断点可以对应一组数据，最终将这些数据点连接即可得到ROC曲线
  - 体现了泛化性能的好坏
  - 若一个学习器的ROC 曲线被另一个学习器的曲线完全"包住"， 则可断言后者的性能优于前者
  - AUC(Area Under ROC Curve)：**反映了样本预测的排序质量**

- 代价曲线

  - 正例概率代价：（p 是样例为正例的概率）
    - ![](https://latex.codecogs.com/gif.latex?P(&plus;)&space;cost=\frac{p&space;\times&space;cost_{01}}{p&space;\times&space;\operatorname{cost}_{01}&plus;(1-p)&space;\times&space;\cos&space;t_{10}})
  - 归一化代价：（p 是样例为正例的概率）
    - ![](https://latex.codecogs.com/gif.latex?\operatorname{cost}_{n&space;o&space;r&space;m}=\frac{\operatorname{FNR}&space;\times&space;p&space;\times&space;cost_{01}&plus;\operatorname{FPR}&space;\times(1-p)&space;\times&space;cost_{10}}{p&space;\times&space;cost_{01}&plus;(1-p)&space;\times&space;cost_{10}})
  - 代价曲线与期望总体代价：
    - ![image-20200614222738117](https://i.loli.net/2020/06/14/mlrXY2SjaNH9yB6.png)
    - 上图的**横轴为正例概率代价，纵轴为归一化代价**
    - ROC曲线上的每一个点对应一条代价曲线，根据（FPR, TPR）可以求出FNR，连接（0，FPR）与（1，FNR）即可得到代价平面中的一条线段，**所有的这些线段与X轴所围成的面积即为“期望总体代价”**

## 各种曲线的实现

```python
import matplotlib.pyplot as plt
from itertools import cycle
import numpy as np

# 输入数据
real_label = [0,0,0,1,0,1,1,1,0]  # 真实标签
y_predict = [0.1234,0.56789,0.2345,0.6789,0.3456,0.4567,0.5,0.89,0.01]  # 假定分类器输出的原始数值

'''
输入：阈值，分类器的预测值
输出：根据阈值判断的预测标签
逻辑：大于等于阈值的预测值判定为正例，注意此处需要包含等于，否则求后续的查准率时会出现将所有预测结果都判定为负的情况，
此情况会使得查准率分母中的FP+TP=0，不利于我们处理
'''
def predict(threshold, y_predict):
    if threshold < 0 or threshold > 1:
        raise ValueError("输入了错误的阈值")
    predict_label = []
    for i in y_predict:
        if i < threshold:
            predict_label.append(0)
        else:
            predict_label.append(1)
    return predict_label
        
'''
输入：真实标签，预测标签
输出：FPR, TPR, FNR, TNR, 正例查准率，正例查全率，反例查准率，反例查全率，真实标签中的正例占比
'''
def indicators(real_label, predict_label):
    if len(real_label) != len(predict_label):
        raise ValueError("预测标签与实际标签长度不相等")
    FP = TP = FN = TN = 0
    for i in range(len(real_label)):
        if real_label[i] == predict_label[i]:
            if real_label[i] == 1:
                TP += 1
            else:
                TN += 1
        else:
            if real_label[i] == 1:
                FN += 1
            else:
                FP += 1
    print(f"TP = {TP}, FP = {FP}, TN = {TN}, FN = {FN}")
    FPR = FP / (FP+TN)  # 也可以写作1-TNR
    TPR = TP / (TP+FN)  # 也可以写作1-FNR
    FNR = FN / (TP+FN)  # 也可以写作1-TPR
    TNR = TN / (FP+TN)  # 也可以写作1-FPR
    positive_precision = TP / (TP+FP) if not (TP+FP) == 0 else 0
    positive_recall = TPR  # 正例查准率与真正例率是相等的
    negative_precision = TN / (TN+FN) if not (TN+FN) == 0 else 0
    negative_recall = TNR  #反例查准率与真反例率是相等的
    print(f"FPR = {FPR}, TPR = {TPR}, FNR = {FNR}, TNR = {TNR}")
    print(f"positive_precision = {positive_precision}, positive_recall = {positive_recall}")
    print(f"negative_precision = {negative_precision}, negative_recall = {negative_recall}")
    pos_label_rate = real_label.count(1) / len(real_label)
    print(f"pos_label_rate = {pos_label_rate}")
    print("\n")
    return FPR, TPR, FNR, TNR, positive_precision, positive_recall, negative_precision, negative_recall, pos_label_rate


'''
输入：真实标签，分类器的预测值
输出：FPR, TPR, FNR, TNR, 正例查准率，正例查全率，反例查准率，反例查全率，真实标签中的正例占比在不同阈值下的值
'''
def diff_threshold(real_label,y_predict):
    sorted_pair = sorted(zip(real_label,y_predict), key = lambda x : x[1], reverse=True)
    print(f"sorted_pair = {sorted_pair}")
    print(f"real_label = {real_label}")
    print("\n")
    FPR_list = []
    TPR_list = []
    FNR_list = []
    TNR_list = []
    positive_precision_list = []
    positive_recall_list = []
    negative_precision_list = []
    negative_recall_list = []
    pos_label_rate_list = []
    for (label, predict_value) in sorted_pair:  # 实际上是不需要排序的，此处只是为了说明数据点本身具有排序的含义
        threshold = predict_value  # 遍历预测值作为阈值
        predict_label = predict(threshold, y_predict)  # 根据阈值判断的预测标签
        print(f"threshold = {threshold}, predict_label = {predict_label}")
        FPR, TPR, FNR, TNR, positive_precision, positive_recall, negative_precision, negative_recall, pos_label_rate = indicators(real_label, predict_label)
        FPR_list.append(FPR)
        TPR_list.append(TPR)
        FNR_list.append(FNR)
        TNR_list.append(TNR)
        positive_precision_list.append(positive_precision)
        positive_recall_list.append(positive_recall)
        negative_precision_list.append(negative_precision)
        negative_recall_list.append(negative_recall)
        pos_label_rate_list.append(pos_label_rate)
    return FPR_list, TPR_list, FNR_list, TNR_list, positive_precision_list, positive_recall_list, negative_precision_list, negative_recall_list, pos_label_rate_list
    
    
'''
输入：FPR, FNR在不同阈值下的值
输出：代价曲线
'''    
def cost_curve(FPR_list, FNR_list):
    plt.figure()
    colors = cycle(['black','grey','brown','red','coral','darkorange','gold','purple','royalblue'])
    for i,line_color in zip(range(len(FPR_list)),colors):
        plt.plot([0,1],[FPR_list[i], FNR_list[i]], color = line_color)
    plt.rcParams['font.sans-serif'] = ['SimHei']  # 保证中文标题可以使用
    plt.rcParams['axes.unicode_minus'] = False
    plt.xlim([0.0, 1.0])  # 横坐标从0→1
    plt.ylim([0.0, 1.05])  # 纵坐标从0→1.05
    plt.xticks(np.arange(0, 1.1, 0.1))  # 坐标的间隔
    plt.yticks(np.arange(0, 1.1, 0.1))
    plt.xlabel('正例概率代价')
    plt.ylabel('归一化代价')
    plt.title('代价曲线')
    plt.show()
    return


'''
输入：正例查准率和正例查全率在不同阈值下的值
输出：P-R曲线
'''    
def pr_curve(positive_precision_list, positive_recall_list):
    # 前后加入（0,1）与（1,0）两个点方便观察
    positive_precision_list.insert(0,1)
    positive_precision_list.insert(-1,0)
    positive_recall_list.insert(0,0)
    positive_recall_list.insert(-1,1)
    plt.figure()
    plt.plot(positive_recall_list,positive_precision_list,color = 'red')
    plt.rcParams['font.sans-serif'] = ['SimHei']  # 保证中文标题可以使用
    plt.rcParams['axes.unicode_minus'] = False
    plt.xlim([0.0, 1.05])  # 横坐标从0→1
    plt.ylim([0.0, 1.05])  # 纵坐标从0→1.05
    plt.xticks(np.arange(0, 1.1, 0.1))  # 坐标的间隔
    plt.yticks(np.arange(0, 1.1, 0.1))
    plt.xlabel('查全率')
    plt.ylabel('查准率')
    plt.title('P-R曲线')
    plt.show()


'''
输入：FPR,TPR在不同阈值下的值
输出：ROC曲线与对应的AUC值
'''
def roc_curve(FPR_list, TPR_list):
    auc = 0
    for i in range(len(FPR_list)-1):
        auc += 0.5*(FPR_list[i+1]-FPR_list[i])*(TPR_list[i]+TPR_list[i+1])  # 可参考西瓜书公式2.20（P35）
    plt.figure()
    plt.plot(FPR_list,TPR_list,color = 'blue', label = 'ROC curve (area = {0:0.2f})'
                   .format(auc))
    plt.rcParams['font.sans-serif'] = ['SimHei']  # 保证中文标题可以使用
    plt.rcParams['axes.unicode_minus'] = False
    plt.xlim([0.0, 1.05])  # 横坐标从0→1
    plt.ylim([0.0, 1.05])  # 纵坐标从0→1.05
    plt.xticks(np.arange(0, 1.1, 0.1))  # 坐标的间隔
    plt.yticks(np.arange(0, 1.1, 0.1))
    plt.xlabel('假正例率(FPR)')
    plt.ylabel('真正例率(TPR)')
    plt.legend(loc="lower right")
    plt.title('ROC曲线')
    plt.show()
        
        
# 主函数
def main(real_label,y_predict):
    FPR_list, TPR_list, FNR_list, TNR_list, positive_precision_list, positive_recall_list, negative_precision_list, negative_recall_list, pos_label_rate_list = diff_threshold(real_label,y_predict)
    cost_curve(FPR_list, FNR_list)  # 代价曲线
    pr_curve(positive_precision_list, positive_recall_list)  # P-R曲线
    roc_curve(FPR_list, TPR_list)  # ROC曲线
    

main(real_label,y_predict)


```

   

​    sorted_pair = [(1, 0.89), (1, 0.6789), (0, 0.56789), (1, 0.5), (1, 0.4567), (0, 0.3456), (0, 0.2345), (0, 0.1234), (0,   0.01)]
​    real_label = [0, 0, 0, 1, 0, 1, 1, 1, 0]


​    threshold = 0.89, predict_label = [0, 0, 0, 0, 0, 0, 0, 1, 0]
​    TP = 1, FP = 0, TN = 5, FN = 3
​    FPR = 0.0, TPR = 0.25, FNR = 0.75, TNR = 1.0
​    positive_precision = 1.0, positive_recall = 0.25
​    negative_precision = 0.625, negative_recall = 1.0
​    pos_label_rate = 0.4444444444444444


​    threshold = 0.6789, predict_label = [0, 0, 0, 1, 0, 0, 0, 1, 0]
​    TP = 2, FP = 0, TN = 5, FN = 2
​    FPR = 0.0, TPR = 0.5, FNR = 0.5, TNR = 1.0
​    positive_precision = 1.0, positive_recall = 0.5
​    negative_precision = 0.7142857142857143, negative_recall = 1.0
​    pos_label_rate = 0.4444444444444444


​    
​    threshold = 0.56789, predict_label = [0, 1, 0, 1, 0, 0, 0, 1, 0]
​    TP = 2, FP = 1, TN = 4, FN = 2
​    FPR = 0.2, TPR = 0.5, FNR = 0.5, TNR = 0.8
​    positive_precision = 0.6666666666666666, positive_recall = 0.5
​    negative_precision = 0.6666666666666666, negative_recall = 0.8
​    pos_label_rate = 0.4444444444444444


​    
​    threshold = 0.5, predict_label = [0, 1, 0, 1, 0, 0, 1, 1, 0]
​    TP = 3, FP = 1, TN = 4, FN = 1
​    FPR = 0.2, TPR = 0.75, FNR = 0.25, TNR = 0.8
​    positive_precision = 0.75, positive_recall = 0.75
​    negative_precision = 0.8, negative_recall = 0.8
​    pos_label_rate = 0.4444444444444444


​    
​    threshold = 0.4567, predict_label = [0, 1, 0, 1, 0, 1, 1, 1, 0]
​    TP = 4, FP = 1, TN = 4, FN = 0
​    FPR = 0.2, TPR = 1.0, FNR = 0.0, TNR = 0.8
​    positive_precision = 0.8, positive_recall = 1.0
​    negative_precision = 1.0, negative_recall = 0.8
​    pos_label_rate = 0.4444444444444444


​    
​    threshold = 0.3456, predict_label = [0, 1, 0, 1, 1, 1, 1, 1, 0]
​    TP = 4, FP = 2, TN = 3, FN = 0
​    FPR = 0.4, TPR = 1.0, FNR = 0.0, TNR = 0.6
​    positive_precision = 0.6666666666666666, positive_recall = 1.0
​    negative_precision = 1.0, negative_recall = 0.6
​    pos_label_rate = 0.4444444444444444


​    
​    threshold = 0.2345, predict_label = [0, 1, 1, 1, 1, 1, 1, 1, 0]
​    TP = 4, FP = 3, TN = 2, FN = 0
​    FPR = 0.6, TPR = 1.0, FNR = 0.0, TNR = 0.4
​    positive_precision = 0.5714285714285714, positive_recall = 1.0
​    negative_precision = 1.0, negative_recall = 0.4
​    pos_label_rate = 0.4444444444444444


​    
​    threshold = 0.1234, predict_label = [1, 1, 1, 1, 1, 1, 1, 1, 0]
​    TP = 4, FP = 4, TN = 1, FN = 0
​    FPR = 0.8, TPR = 1.0, FNR = 0.0, TNR = 0.2
​    positive_precision = 0.5, positive_recall = 1.0
​    negative_precision = 1.0, negative_recall = 0.2
​    pos_label_rate = 0.4444444444444444


​    
​    threshold = 0.01, predict_label = [1, 1, 1, 1, 1, 1, 1, 1, 1]
​    TP = 4, FP = 5, TN = 0, FN = 0
​    FPR = 1.0, TPR = 1.0, FNR = 0.0, TNR = 0.0
​    positive_precision = 0.4444444444444444, positive_recall = 1.0
​    negative_precision = 0, negative_recall = 0.0
​    pos_label_rate = 0.4444444444444444

![image-20200615022818077](https://i.loli.net/2020/06/15/n9NEVgishxXFLRI.png)

![image-20200615022836592](https://i.loli.net/2020/06/15/8UzZSpjaibfXrw3.png)

![image-20200615022902874](https://i.loli.net/2020/06/15/3b5gAKwOnYNaWrv.png)

## 比较检验

原因：

- 测试集上的性能不能完全代表泛化性能
- 测试集的变化会导致测试集上的性能变化
- 机器学习算法具有随机性

检验方法（核心思想：在某一置信度下，通过测试错误率推出学习器的泛化错误率的最大值，如超出该最大值，则该假设可以被拒绝）：

- 二项检验
- t检验
- 交叉验证t检验
- McNemar检验
- Friedman 检验与Nemenyi后续检验

## 偏差与方差

泛化误差可分解为偏差、方差与噪声之和

- Y_D 为x在数据集中的标记， y为x的真实标记， f(x; D) 为训练集D上学得模型 f 在x上的预测输出.
- 方差：度量了同样大小的训练集的变动所导致的学习性能的变化
  - ![](https://latex.codecogs.com/gif.latex?%5Coperatorname%7Bvar%7D%28%5Cboldsymbol%7Bx%7D%29%3D%5Cmathbb%7BE%7D_%7BD%7D%5Cleft%5B%28f%28%5Cboldsymbol%7Bx%7D%20%3B%20D%29-%5Cbar%7Bf%7D%28%5Cboldsymbol%7Bx%7D%29%29%5E%7B2%7D%5Cright%5D)
- 偏差：度量了学习算法的期望预测与真实结果的偏离程度
  - ![](https://latex.codecogs.com/gif.latex?%5Coperatorname%7Bbias%7D%5E%7B2%7D%28%5Cboldsymbol%7Bx%7D%29%3D%28%5Cbar%7Bf%7D%28%5Cboldsymbol%7Bx%7D%29-y%29%5E%7B2%7D)
- 噪声：表达了在当前任务上任何学习算法所能达到的期望泛化误差的下界
  - ![](https://latex.codecogs.com/gif.latex?\varepsilon^{2}%3D\mathbb{E}_{D}\left[\left(y_{D}-y\right)^{2}\right])
- 泛化误差
  - ![](https://latex.codecogs.com/gif.latex?E(f%3BD)%3D\operatorname{bias}^{2}(\boldsymbol{x})&plus;\operatorname{var}(\boldsymbol{x})&plus;\varepsilon^{2})

- 训练各阶段方差与偏差的影响：
  - 在训练不足时，学习器的拟合能力不够强，训练数据的扰动不足以使得学习器产生显著变化，此时偏差主导了泛化错误率
  - 随着训练程度的加深，学习器的拟合能力逐渐增强，训练数据发生的扰动渐渐能被学习器学到，方差
    逐渐主导了泛化错误率
  - 在训练程度充足后，学习器的拟合能力已非常强，训练数据发生的轻微扰动都会导致学习器发生显著变化，若训练数据自身的、非全局的特性被学习器学到了，则将发生过拟合.