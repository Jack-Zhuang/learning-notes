# 第2章 模型评估与选择

部分内容不一定在书中

## 过拟合与欠拟合

- 过拟合 (overfitting)：对训练样本学习过度，导致泛化性能下降（此问题无法彻底避免）
  - 解决方法：正则化等
- 欠拟合 (underfitting)：对训练样本学习不足，导致泛化性能不足
  - 解决方法：增加训练轮数等

## 误差分类

- 期望风险：对所有样本（包含未知样本和已知的训练样本）的预测能力
  - 反映模型的泛化能力
  - 在实际操作中往往用测试误差作为泛化误差的近似
  - **测试集应尽可能与训练集互斥，但需要同分布**
- 经验风险：对已知的训练样本的预测能力
  - 反映了训练误差
  - **过分追求经验误差（风险）最小化容易导致过拟合问题**
- 结构风险：反映了模型的复杂度（例如参数维度）
  - 可以认为**期望风险 = 经验风险 + 结构风险**，因此在选择模型和衡量误差时希望追求经验风险最小化以及结构风险最小化的平衡 （进一步引申：VC维）
  - 常用方法：添加正则项：比如“**L1正则化”、“L2正则化**”

## 数据集划分方法

- 留出法：直接将数据集D 划分为两个互斥的集合
  - 训练/测试集的划分要尽可能保持数据分布的一致性，避免因数据划分过程引入额外的偏差而对最终结果产生影响
  - 在分类任务中至少要保持样本的类别比例相似
  - 优点：简单
  - 缺点：单次使用留出法得到的估计结果往往**不够稳定可靠，需多次重复求平均**
  - 常见做法是将大约$\frac{2}{3}$ ~ $\frac{4}{5}$的样本用于训练，剩余样本用于测试
- 交叉验证法：将数据集D划分为k个大小相似的**互斥**子集，即$D=D_{1} \cup D_{2} \cup \ldots \cup D_{k}, D_{i} \cap D_{j}=\varnothing(i \neq j)$，每个子集都尽可能保证数据分布的一致性，即从D 中通过分层采样得到.每次用k-1 个子集的并集作为训练集，余下的那个子集作为测试集；这样就可获得k组训练/测试集，从而可进行k次训练和测试，最终返回的是这k个测试结果的均值
  - 常用10折交叉
  - 特殊情况：留一法
- 自助法：从数据集D中有放回的抽取样本组成训练集D’ （D与D’的样本数相同但样本分布有所不同，大约有36.8%的样本不会被包含在采样数据集中），于是可以用D‘作为训练集，D\D’作为测试集
  - 优点：
    - 在数据集较小、难以有效划分训练/测试集时很有用
    - 能从初始数据集中**产生多个不同的训练集**，对集成学习等方法有很大的好处
  - 缺点：
    - 改变了初始数据集的分布，这会**引入估计偏差**

## 采样方法

分层采样：保留类别比例的采样方式

## 调参

- 参数范围
  - 超参数可以变化的范围
- 移动步长
  - 超参数的调整步长
- 流程
  - 分割数据集为
    - 训练集（见第一章）
    - 测试集（见第一章）
    - 验证集（validation set）：可以认为验证集是用来调参的，即同一模型可以有多组超参数（hyper-parameters），每次调整参数后在验证集中验证模型性能，从而选出较优的超参组合。测试集由始至终都不能参与到训练和参数调整中，如此才能保证泛化能力估计的准确性，如果使用测试集来进行参数调整，相当于学习器学习了测试集中的内容，此时测试集对于学习器就不是一个全新的内容，不符合估计泛化能力的要求。

- 引申
  - 调参记录：fitlog，tensorboardx等
  - 自动调参：AutoML（grid search，random search，NAS等）

## 评估指标

### 回归任务

- 均方误差
  - $E(f ; D)=\frac{1}{m} \sum_{i=1}^{m}\left(f\left(x_{i}\right)-y_{i}\right)^{2}$

### 分类任务

- 精度/准确率（accuracy）

  - $E(f ; D)=\frac{1}{m} \sum_{i=1}^{m} \mathbb{I}\left(f\left(\boldsymbol{x}_{i}\right) \neq y_{i}\right)$

- 错误率

  - $\begin{aligned} \operatorname{acc}(f ; D) &=\frac{1}{m} \sum_{i=1}^{m} \mathbb{I}\left(f\left(\boldsymbol{x}_{i}\right)=y_{i}\right) \\ &=1-E(f ; D) \end{aligned}$

- 混淆矩阵

  - |              |            预测结果            |            预测结果            |
    | :----------: | :----------------------------: | :----------------------------: |
    | **真实情况** |              正例              |              反例              |
    |     正例     | TP（真正例，预测为真实际为真） | FN（假反例，预测为假实际为真） |
    |     反例     | FP（假正例，预测为真实际为假） | TN（真反例，预测为反实际为反） |

- 查准率（precision）

  - $P=\frac{T P}{T P+F P}$

- 查全率（recall）/ 真正例率（TPR）

  - $R=\frac{T P}{T P+F N}$

- P-R曲线

  - ![image-20200613104733753](https://i.loli.net/2020/06/13/gVJCbOc7Sxvf8G3.png)
  - 衡量方法
    - 曲线下面积（不易估算）
    - 平衡点(Break-Event Point，简称BEP)：是" 查准率=查全率"时的取值，BEP越大学习器效果越好
    - F1度量（基于查准率和查全率的调和平均）
      - $\frac{1}{F 1}=\frac{1}{2} \cdot\left(\frac{1}{P}+\frac{1}{R}\right)$
      - $F 1=\frac{2 \times P \times R}{P+R}=\frac{2 \times T P}{\text { 样例总数 }+T P-T N}$
    - $f_{\beta}$度量
      - $\frac{1}{F_{\beta}}=\frac{1}{1+\beta^{2}} \cdot\left(\frac{1}{P}+\frac{\beta^{2}}{R}\right)$
      - $F_{\beta}=\frac{\left(1+\beta^{2}\right) \times P \times R}{\left(\beta^{2} \times P\right)+R}$
    - 当存在多个混淆矩阵时（如多次训练，多个数据集，多分类任务）

- ROC曲线

- 代价曲线

