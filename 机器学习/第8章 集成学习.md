# 第8章 集成学习

## 个体与集成

### 概念

- 集成学习：又称为多分类器系统、基于委员会的学习等
- 个体学习器：由一个现有的学习算法从训练数据产生，又称为基学习器
- 集成学习器：分为同质集成与异质集成
  - 同质集成：个体学习器相同
  - 异质集成：个体学习器不同，此时不称作基学习器，而称作“组件学习器”

### 集成学习的优点

- 泛化能力更强

### 集成学习的要求

- 个体学习器要有一定的准确性，并且要有多样性

- 根据Hoeffding不等式，集成的错误率为

  ![image-20200815115821717](https://i.loli.net/2020/08/15/f2gmps9khw6tJ5o.png)

  随着个体分类器数目T的增大，集成的错误率将指数级下降，最终趋向于零

### 集成学习的关键假设及其带来的问题

- 关键假设：基学习器的误差相互独立，这个假设在现实任务中显然不成立，因为个体学习器是为解决同一个问题训练出来的
- 冲突：个体学习器的“准确性”和“多样性”本身就存在冲突，准确性很高之后，要增加多样性就需牺牲准确性

### 集成学习的分类

- 个体学习器之间存在强依赖关系，必须串行生成的序列化方法：boosting
- 个体学习器之间不存在强依赖关系，可同时生成的并行化方法：bagging和随机森林

## Boosting

### 工作机制

- 先从初始训练集训练出一个基学习器，再根据基学习器的表现对训练样本分布进行调整，使得先前基学习器做错的训练样本在后续受到更多关注，然后基于调整后的样本分布来训练下一个基学习器;如此重复进行，直至基学习器数目达到事先指定的值T， 最终将这T个基学习器进行加权结合

## Bagging与随机森林

## 结合策略

## 多样性

